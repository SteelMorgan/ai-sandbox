## Client sandbox env (NON-SECRETS ONLY).
## Sensitive values must come from Docker secrets files.

# Global settings for custom OpenAI backend
CUSTOM_OPENAI_ENABLED=1
OPENAI_BASE_URL=https://ai.gbig.holdings/v1

# Settings for Claude Code
CC_HELPER_VALIDATE_MODE=anthropic
CC_HELPER_MODEL=sonnet
CC_HELPER_ALIAS_OPUS=opus
CC_HELPER_ALIAS_SONNET=sonnet
CC_HELPER_ALIAS_HAIKU=haiku
CC_HELPER_API_TIMEOUT_MS=30000
CC_HELPER_DISABLE_NONESSENTIAL_TRAFFIC=1
CC_HELPER_SKIP_VALIDATE=0
CC_HELPER_SKIP_UPDATE=1

# Codex bootstrap settings
# Default model (if CODEX_MODELS is empty):
CODEX_MODEL=cx/gpt-5.3-codex
# Optional list for generating [profiles.*] in ~/.codex/config.toml:
CODEX_MODELS=cx/gpt-5.3-codex, cx/gpt-5.3-codex-xhigh, cx/gpt-5.3-codex-high, cx/gpt-5.3-codex-low, cx/gpt-5.3-codex-none, cx/gpt-5.3-codex-spark, cx/gpt-5.1-codex-mini, cx/gpt-5.1-codex-mini-high, cx/gpt-5.2-codex, cx/gpt-5.2, cx/gpt-5.1-codex-max, cx/gpt-5.1-codex, cx/gpt-5.1, cx/gpt-5-codex, cx/gpt-5-codex-mini, ag/gemini-3.1-pro-high, ag/gemini-3.1-pro-low, ag/gemini-3-flash, ag/gpt-oss-120b-medium
# Optional custom provider fields:
CODEX_MODEL_PROVIDER_ID=9R
CODEX_MODEL_PROVIDER_NAME=9Router
CODEX_WIRE_API=responses
# Optional cloud source for model metadata used in generated model-catalog.json:
CODEX_SOURCE_MODELS_URL=https://raw.githubusercontent.com/openai/codex/main/codex-rs/core/models.json
# Optional local map file for custom aliases (cx/* -> upstream slug):
CODEX_MODEL_MAP_FILE=/workspaces/work/.devcontainer/codex-model-map.json
# Optional manual overrides for models without upstream mapping (e.g. ag/*):
CODEX_MODEL_OVERRIDES_FILE=/workspaces/work/.devcontainer/codex-model-overrides.json
# Optional prompt file for Gemini base_instructions:
CODEX_GEMINI_PROMPT_FILE=/workspaces/work/.devcontainer/gemini-promt.md

# Settings for Gemini CLI
GEMINI_MODEL=gemini-pro-high
GEMINI_MODEL_PRO_LOW=gemini-pro-low
GEMINI_MODEL_FLASH=gemini-3-flash
